# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python
pr: none
trigger:
  branches:
    include:
    - '*'

stages:
#- stage: static_checks
#  displayName: Static Checks
#  dependsOn: []
#  jobs:
#    - job:
#      displayName: "Check Git Tags"
#      steps:
#      - script: echo "##vso[build.addbuildtag]Automated"
#        condition: startsWith(variables['Build.SourceBranch'], 'refs/tags/')

#- stage: test_and_build
#  displayName: 'Test and build'
#  dependsOn: []
#  jobs:
#    - job:
#      displayName: ' '
#      strategy:
#        matrix:
#          python36:
#            PYTHON_VERSION: '3.6'
#          python37:
#            PYTHON_VERSION: '3.7'
#          python38:
#            PYTHON_VERSION: '3.8'
#      pool:
#        vmImage: 'ubuntu-18.04'
#      steps:
#        - task: UsePythonVersion@0
#          inputs:
#            versionSpec: $(PYTHON_VERSION)
#        - script: |
#            pip install -U pip
#            pip install -U -r requirements.txt
#          displayName: 'Install requirements'
#        - script: |
#            pytest --cov=anonlinkclient --junitxml=testResults.xml  --cov-report=xml:coverage.xml
#          displayName: 'Tests'
#          timeoutInMinutes: 10  # it should pass in 2.5 minutes, so 10 should be more than enough even if server is busy
#          env:
#            TEST_ENTITY_SERVICE: 'https://testing.es.data61.xyz'
#
#        # Test tutorial Jupyter notebooks in docs
#        - script: |
#            pip install -e .
#            python -m pip install -U -r docs/doc-requirements.txt
#            pytest --nbval docs
#          displayName: 'Test all notebooks'
#
#        - bash: |
#            pip install -U pip codecov
#            report_name="ubuntu18-04_$(PYTHON_VERSION)"
#            python -m codecov --token $(CODECOV_TOKEN) \
#              --file coverage.xml \
#              -n ${report_name}
#          displayName: 'Send coverage to codecov'
#          condition: succeededOrFailed()

#- stage: package
#  displayName: Package Artifacts
##  dependsOn: ['test_and_build']
#  jobs:
#  - job:
#    displayName: 'Package Artifacts'
#    pool:
#      vmImage: 'ubuntu-16.04'
#    steps:
#    - task: DownloadPipelineArtifact@2
#      inputs:
#        path: $(Pipeline.Workspace)
#
#    - script: |
#        cd $(Pipeline.Workspace)
#        mkdir artifacts
#        mv vs2017-win2016-3.7-x64/*.exe artifacts
#        mv vs2017-win2016-3.7-x86/*.exe artifacts
#        mv ubuntu-18.04-3.7-x64/*.whl artifacts
#        mv sdist/* artifacts
#        ls artifacts
#      displayName: 'List Artifacts'
#    - task: PublishPipelineArtifact@1
#      inputs:
#        artifact: 'release'
#        targetPath: '$(Pipeline.Workspace)/artifacts'
#
#- stage: package
#  displayName: Build Wheel Packages
#  dependsOn: []
#  jobs:
#    - job: linux
#      pool: {vmImage: 'Ubuntu-16.04'}
#      strategy:
#        matrix:
#          Python36:
#            python.version: '3.6'
#          Python37:
#            python.version: '3.7'
#          Python38:
#            python.version: '3.8'
#
#      steps:
#        - task: UsePythonVersion@0
#          inputs:
#            versionSpec: '$(python.version)'
#          displayName: 'Use Python $(python.version)'
#
#        - script:
#            pip install wheel
#          displayName: 'Install wheel'
#
#        # artifact creation
#        - script:
#            python setup.py sdist bdist_wheel
#          displayName: 'Artifact creation'
#
#        # copy artifact
#        - task: CopyFiles@2
#          inputs:
#            targetFolder: $(Build.ArtifactStagingDirectory)
#
#        # publish artifact
#        - task: PublishBuildArtifacts@1
#          inputs:
#            PathtoPublish: '$(Build.ArtifactStagingDirectory)'
#            ArtifactName: 'dist'
#            publishLocation: 'Container'
#

#    - job: macos
#      pool: {vmImage: 'macOS-10.13'}
#      steps:
#        - task: UsePythonVersion@0
#        - bash: |
#            python -m pip install --upgrade pip
#            pip install cibuildwheel==1.1.0
#            cibuildwheel --output-dir wheelhouse .
#        - task: PublishBuildArtifacts@1
#          inputs: {pathtoPublish: 'wheelhouse'}
#
#    - job: windows
#      pool: {vmImage: 'vs2017-win2016'}
#      steps:
#        - task: UsePythonVersion@0
#        - script: choco install vcpython27 -f -y
#          displayName: Install Visual C++ for Python 2.7
#        - bash: |
#            python -m pip install --upgrade pip
#            pip install cibuildwheel==1.1.0
#            cibuildwheel --output-dir wheelhouse .
#        - task: PublishBuildArtifacts@1
#          inputs: {pathtoPublish: 'wheelhouse'}
#
#
#- stage: package
#  displayName: Package Artifacts
#  dependsOn: []
#  jobs:
#  - job:
#    displayName: 'Package Artifacts'
#    pool:
#      vmImage: 'ubuntu-16.04'
#    steps:
#    - {task: UsePythonVersion@0, inputs: {versionSpec: '3.7', architecture: x64}}
#    - task: DownloadPipelineArtifact@2
#      inputs:
#        path: $(Pipeline.Workspace)
#
#    - script: |
#        cd $(Pipeline.Workspace)
#        mkdir artifacts
#        mv vs2017-win2016-3.7-x64/*.exe artifacts
#        mv vs2017-win2016-3.7-x86/*.exe artifacts
#        mv ubuntu-18.04-3.7-x64/*.whl artifacts
#        mv sdist/* artifacts
#        ls artifacts
#      displayName: 'List Artifacts'
#    - task: PublishPipelineArtifact@1
#      inputs:
#        artifact: 'release'
#        targetPath: '$(Pipeline.Workspace)/artifacts'

- stage: publish
  dependsOn: []
  displayName: Publish to test feed
  jobs:
  - job:
    pool:
      vmImage: 'ubuntu-latest'
    steps:
      - {task: UsePythonVersion@0, inputs: {versionSpec: '3.8', architecture: x64}}
      - script: 'pip install twine'
      - task: DownloadPipelineArtifact@2
        inputs:
#          artifactName: 'drop'
#          patterns: '**/*.whl'
          path: $(Pipeline.Workspace)
      - script: 'python setup.py sdist -d $(Pipeline.Workspace)/dist'

      - task: TwineAuthenticate@1
        inputs:
          artifactFeed: 'anonlink, anonlink_client'
      - script: 'twine upload -r anonlink/anonlinke_client --config-file $(PYPIRC_PATH) $(Pipeline.Workspace)/dist/* --skip-existing'